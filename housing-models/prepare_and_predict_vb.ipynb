{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "#cleanup tasks - venkata\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "scaler = StandardScaler()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_df = pd.read_csv('../docs/test.csv')\n",
    "# test_df.head()\n",
    "train_df = pd.read_csv('../docs/train.csv')\n",
    "train_df.head()\n",
    "\n",
    "# missing_values_in_test = test_df.isnull().sum()\n",
    "# print(missing_values_in_test)\n",
    "\n",
    "def remove_highly_correlated_features(train_df, test_df, threshold=0.85):\n",
    "    # Compute the correlation matrix\n",
    "    corr_matrix = train_df.corr(numeric_only=True)\n",
    "\n",
    "    to_drop = [column for column in corr_matrix.columns if any(corr_matrix[column] > threshold)]\n",
    "\n",
    "    # Drop the highly correlated columns\n",
    "    train_df = train_df.drop(columns=to_drop)\n",
    "    test_df = test_df.drop(columns=to_drop)\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def process_correlation(train_df, test_df):\n",
    "    # Compute the correlation matrix\n",
    "    correlation_matrix = train_df.corr(numeric_only=True)\n",
    "\n",
    "    # Visualize the correlation matrix\n",
    "    # plt.figure(figsize=(10, 8))\n",
    "    # sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "    # plt.title('Correlation Matrix')\n",
    "    # plt.show()\n",
    "    remove_highly_correlated_features(train_df, test_df)\n",
    "\n",
    "def preprocess_data(train_df, test_df):\n",
    "\n",
    "    # Identify numerical and categorical columns\n",
    "    numerical_cols = train_df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_cols = train_df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "    # Scale numerical columns\n",
    "    scaler = StandardScaler()\n",
    "    train_df[numerical_cols] = scaler.fit_transform(train_df[numerical_cols])\n",
    "    test_df[numerical_cols] = scaler.transform(test_df[numerical_cols])\n",
    "    # Encode categorical columns\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    encoded_categorical = encoder.fit_transform(train_df[categorical_cols])\n",
    "    encoded_categorical_test = encoder.transform(test_df[categorical_cols])\n",
    "    # Convert encoded values to a DataFrame\n",
    "    encoded_categorical_df = pd.DataFrame(\n",
    "        encoded_categorical,\n",
    "        columns=encoder.get_feature_names_out(categorical_cols),\n",
    "        index=train_df.index\n",
    "    )\n",
    "    encoded_categorical_df_test = pd.DataFrame(encoded_categorical_test,\n",
    "        columns=encoder.get_feature_names_out(categorical_cols),\n",
    "        index=test_df.index\n",
    "    )\n",
    "    # Drop original categorical columns and concatenate the encoded DataFrame\n",
    "    train_df = pd.concat([train_df.drop(categorical_cols, axis=1), encoded_categorical_df], axis=1)\n",
    "    test_df = pd.concat([test_df.drop(categorical_cols, axis=1), encoded_categorical_df_test], axis=1)\n",
    "\n",
    "    # Align the train and test DataFrames\n",
    "    train_df = train_df.drop(columns=['Id'])  # Drop ID column\n",
    "    test_ids = test_df['Id']\n",
    "    test_df = test_df.drop(columns=['Id'])\n",
    "\n",
    "    # process correlation features\n",
    "    process_correlation(train_df, test_df)\n",
    "\n",
    "    return train_df, test_df"
   ],
   "id": "6c490f7edc1c1c6c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T08:05:04.387066Z",
     "start_time": "2025-04-12T08:05:04.376696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_training_data():\n",
    "    global y_train, y_test, X_train_ready, X_test_ready\n",
    "    # Load the dataset\n",
    "    X = train_df.drop('SalePrice', axis=1)  # Replace 'target_column' with the actual target column name\n",
    "    y = train_df['SalePrice']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    # preprocess\n",
    "    X_train_ready, X_test_ready = preprocess_data(X_train, X_test)\n",
    "    print(X_train_ready.info())\n",
    "    return X_train_ready, X_test_ready, y_train, y_test\n"
   ],
   "id": "7a2adaa8e56762d5",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T08:05:15.037709Z",
     "start_time": "2025-04-12T08:05:06.283054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = get_training_data()\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_ready, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "predictions_rf = model.predict(X_test_ready)\n",
    "X_test_ready['SalePriceRF'] = predictions_rf\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(y_test, predictions_rf)\n",
    "\n",
    "# Calculate the root mean squared error\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Print the result\n",
    "print(f\"Root Mean Squared Error of Random Forest: {rmse}\")\n",
    "print(X_test_ready.head())"
   ],
   "id": "dfb091750021e619",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1168 entries, 254 to 1126\n",
      "Columns: 301 entries, MSSubClass to SaleCondition_Partial\n",
      "dtypes: float64(301)\n",
      "memory usage: 2.7 MB\n",
      "None\n",
      "Root Mean Squared Error of Random Forest: 28931.374675911215\n",
      "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
      "892     -0.86676     -0.01382 -0.21159     -0.08893      2.16500   -0.25979   \n",
      "1105     0.07411      1.11141  0.14564      1.37409     -0.52417    0.75122   \n",
      "413     -0.63155     -0.57643 -0.16083     -0.82044      0.37222   -1.43387   \n",
      "522     -0.16111     -0.81755 -0.52903     -0.08893      1.26861   -0.78160   \n",
      "1036    -0.86676      0.74973  0.20534      2.10560     -0.52417    1.17519   \n",
      "\n",
      "      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  SaleType_New  \\\n",
      "892        0.87347    -0.59998     0.47284    -0.28550  ...       0.00000   \n",
      "1105       0.48746     1.49301     1.27699    -0.28550  ...       0.00000   \n",
      "413       -1.68382    -0.59998    -0.97200    -0.28550  ...       0.00000   \n",
      "522       -1.68382    -0.59998    -0.10248    -0.28550  ...       0.00000   \n",
      "1036       1.11472    -0.19526     1.25519    -0.28550  ...       0.00000   \n",
      "\n",
      "      SaleType_Oth  SaleType_WD  SaleCondition_Abnorml  SaleCondition_AdjLand  \\\n",
      "892        0.00000      1.00000                0.00000                0.00000   \n",
      "1105       0.00000      1.00000                0.00000                0.00000   \n",
      "413        0.00000      1.00000                0.00000                0.00000   \n",
      "522        0.00000      1.00000                0.00000                0.00000   \n",
      "1036       0.00000      1.00000                0.00000                0.00000   \n",
      "\n",
      "      SaleCondition_Alloca  SaleCondition_Family  SaleCondition_Normal  \\\n",
      "892                0.00000               0.00000               1.00000   \n",
      "1105               0.00000               0.00000               1.00000   \n",
      "413                0.00000               0.00000               1.00000   \n",
      "522                0.00000               0.00000               1.00000   \n",
      "1036               0.00000               0.00000               1.00000   \n",
      "\n",
      "      SaleCondition_Partial  SalePriceRF  \n",
      "892                 0.00000 141347.25000  \n",
      "1105                0.00000 335328.98000  \n",
      "413                 0.00000 118594.00000  \n",
      "522                 0.00000 152644.00000  \n",
      "1036                0.00000 324495.32000  \n",
      "\n",
      "[5 rows x 302 columns]\n"
     ]
    }
   ],
   "execution_count": 82
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
